
#  Siamese网络与Triplet网络
孪生和三胞胎网络对于学习从图像到紧凑的欧几里得空间的映射非常有用，其中距离对应于相似度的测量[2]。以这种方式训练的Embeddings可以作为特征向量用于分类(classification)或few-shot学习任务。


# 实例 - MNIST


## Baseline - 用softmax分类

我们增加了一个全连接层的类数，用softmax和交叉熵(cross-entropy)训练网络进行分类。网络训练的准确率约为99%。我们从倒数第二层提取2维embeddings。

训练集分布:

![enter image description here](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_softmax_train.png)

测试集:

![enter image description here](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_softmax_test.png)

虽然embeddings看起来是可分离的（这也是我们训练它们的目的），但它们并不具备良好的度量属性。它们可能不是作为新类的描述符的最佳选择。

## Siamese神经网络

现在我们将训练一个Siamese网络，它将一对图像进行训练embeddings，如果它们来自同一类，则它们之间的距离最小化，如果它们代表不同的类，则大于某个余量值。
我们将最小化一个contrastive loss（对比损失）损失函数[1]。

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/contrastive_loss.png)
Pytorch代码实现公式
```
distances = (output2 - output1).pow(2).sum(1) # squared distances  
losses = 0.5 * (target.float() * distances +  
 (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))
 losses.mean() 
```
SiameseMNIST数据集类会随机采样正负对的数据，然后将其喂给Siamese网络。

经过20次迭代的训练，这里是我们得到的训练集的embeddings分布。

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_siamese_train.png)

Test set:

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_siamese_test.png)

学到的embeddings在类内聚类效果更好。

## Triplet网络

我们将训练一个Triplet网络，它需要一个Anchor、一个Positive（与Anchor同级）和Negative（与Anchor不同级）的例子。目标是学习embeddings，使Anchor与Positive的关系比与Negative的关系更接近，并有一定的边际值。

![alt text](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/anchor_negative_positive.png "Source: FaceNet")
Source: *Schroff, Florian, Dmitry Kalenichenko, and James Philbin. [Facenet: A unified embedding for face recognition and clustering.](https://arxiv.org/abs/1503.03832) CVPR 2015.*

**Triplet loss**:   ![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/triplet_loss.png)

Pytorch实现公式
```
distance_positive = (anchor - positive).pow(2).sum(1) # .pow(.5)  
distance_negative = (anchor - negative).pow(2).sum(1) # .pow(.5)  
losses = F.relu(distance_positive - distance_negative + self.margin)
losses.mean()
```
TripletMNIST数据集类会随机每一个Anchor取样一个Positive和Negative的数据，然后将其喂给Triplet网络。

经过20个epochs的训练，这里是我们得到的训练集的嵌入。

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_triplet_train.png)

Test set:

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_triplet_test.png)

学习到的embeddings在类内并不像在siamese网络那样相互接近，但这不是我们优化它们的目的。我们希望embeddings同类的距离更近，不同类的距离更远，我们可以看到这就是训练的方向。

## Online pair/triplet selection - negative mining

siamese和triplet网络有几个问题：
1. 可能的一对/三个**的数量随着数据数量的增加而**二次/三次**。要处理所有的例子是不可行的，训练收敛得很慢。
2. 我们*随机地生成一对/三联体。随着训练的不断进行，越来越多的对/三胞胎是**容易处理的（它们的损失值非常小，甚至是0），*阻止网络的训练*。我们需要为网络提供**难的例子**。
3. 输入到网络中的每幅图像只用于计算一对/三胞胎的对比度/三胞胎损失。计算有些浪费；一旦计算出嵌入，就可以重复用于许多对/三联体。

为了有效地处理这些问题，我们将像分类一样用标准的mini-batch喂给网络。损失函数将负责mini-batch内hard pairs and triplets的选择。如果我们用每10个类16张图片来喂养网络，我们可以处理最多159/\*160/2=12720对和10/\*16/15/2/\*(9/\*16)=172800个三胞胎，而之前的实现中只有80对和53个三胞胎。

通常情况下，在一个小批量内处理所有可能的对子或三胞胎并不是最好的主意。我们可以在[2]和[3]中找到一些关于如何选择三胞胎的策略。

### Online pair selection  
训练过程中选择一对正反向数据

我们将用mini-batch喂养一个网络，就像我们对分类网络所做的那样。这次我们将使用一个特殊的BatchSampler，它将对每个类中的*n_classes*和*n_samples*进行采样，从而得到大小为n_classes / n_samples 的batch size。

对于每个迷你批次，将使用提供的标签选择正负对。

MNIST是一个相当简单的数据集，从随机选取的对子的嵌入已经相当好了，我们看不到这里有什么改进。

**Train embeddings:**

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_ocl_train.png)

**Test embeddings:**

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_ocl_test.png)

### Online triplet selection
训练过程中选择一组目标样本，正向样本，反向样本

我们将像在线配对选择一样，用迷你批次喂养一个网络。在给定标签和预测嵌入的情况下，我们可以使用一些策略来进行三胞胎

选择方案有4种：

- 所有可能的三胞胎
- Hardest negative
- Random hard negative
- Semi-hard negative

选择的策略必须谨慎选择。一个不好的策略可能会导致训练效率低下，甚至更糟糕的是，会导致模型坍塌（所有的嵌入最终都有相同的值）。

下面是我们random hard negatives的结果。

**Training set:**

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_otl_train.png)

**Test set:**

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/mnist_otl_test.png)

# FashionMNIST

Similar experiments were conducted for [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) 数据集也进行了类似的实验，online negative mining的优势略显明显。使用了完全相同的网络架构，只有二维embeddings，这对于学习良好的embeddings可能不够复杂。

更复杂的数据集，更多的classses数量，应该会从online negative mining获益更多。


## Baseline - classification

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/fmnist_softmax_test.png)

## Siamese网络 + online contrastive loss + HardNegativePairSelector 

Siamese network with randomly selected pairs

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/fmnist_comp_cl.png)



![](images/fmnist_comp_ocl.png)

## Triplet + online triplet loss + negative mining

Triplet network with random triplets

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/fmnist_comp_tl.png)

Online triplet loss with negative mining

![](https://raw.githubusercontent.com/adambielski/siamese-triplet/master/images/fmnist_comp_otl.png)

# References

[1] Raia Hadsell, Sumit Chopra, Yann LeCun, [Dimensionality reduction by learning an invariant mapping](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf), CVPR 2006

[2] Schroff, Florian, Dmitry Kalenichenko, and James Philbin. [Facenet: A unified embedding for face recognition and clustering.](https://arxiv.org/abs/1503.03832) CVPR 2015

[3] Alexander Hermans, Lucas Beyer, Bastian Leibe, [In Defense of the Triplet Loss for Person Re-Identification](https://arxiv.org/pdf/1703.07737), 2017

[4] Brandon Amos, Bartosz Ludwiczuk, Mahadev Satyanarayanan, [OpenFace: A general-purpose face recognition library with mobile applications](http://reports-archive.adm.cs.cmu.edu/anon/2016/CMU-CS-16-118.pdf), 2016

[5] Yi Sun, Xiaogang Wang, Xiaoou Tang, [Deep Learning Face Representation by Joint Identification-Verification](http://papers.nips.cc/paper/5416-deep-learning-face-representation-by-joint-identification-verification), NIPS 2014
<!--stackedit_data:
eyJoaXN0b3J5IjpbMzc2MzkwMTAyXX0=
-->